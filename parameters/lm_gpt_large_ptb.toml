n_layer = 36
n_embedding = 1280
n_state_ffn = 5120
n_head = 20
n_context = 1024
residual_dropout = 0.1
attention_dropout = 0.1
embedding_dropout = 0.1
vocab_size = 15432
initializer_range = 0.02

batch_size = 512