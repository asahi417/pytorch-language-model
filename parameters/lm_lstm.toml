batch_size = 80
vocab_size = 15432
embedding_dim = 400
n_hidden_units = 1150
n_layers = 3
sequence_length = 70
tie_weights = true
init_range = 0.1

dropout_word = 0.1
dropout_embedding = 0.65
dropout_intermediate = 0.65
dropout_output = 0.4

lr = 0.001
weight_decay = 1.2e-6
total_steps = 25000

clip = ''
