n_layer = 24
n_embedding = 1024
n_state_ffn = 4096
n_head = 16
n_context = 1024
residual_dropout = 0.1
attention_dropout = 0.1
embedding_dropout = 0.1
vocab_size = 15432
initializer_range = 0.02

batch_size = 512