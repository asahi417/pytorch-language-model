vocab_size = 10000

n_layer = 6
n_head = 8
n_embedding = 512
n_state_ffn = 2048
n_context = 128

dropout_residual = 0.1
dropout_attention = 0.0
dropout_embedding = 0.1

initializer_range = 0.001
batch_size = 64

lr = 0.00025
weight_decay = 0.01
clip = ''
scheduler = 'constant'
warmup_steps = 0
total_steps = 400000
optimizer = 'adamw'
random_seed = 1111